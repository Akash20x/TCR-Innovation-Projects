{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Next Word Prediction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrJQV1Le7yDh"
      },
      "source": [
        "Importing the libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-zFq1MfM295"
      },
      "source": [
        "import tensorflow as tf \n",
        "import string \n",
        "import requests "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lTeShD475Lw"
      },
      "source": [
        "get the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7C_-eNOM4kC"
      },
      "source": [
        "file = open(\"corpus.txt\", \"r\", encoding = \"utf8\")\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZCNlN_P6GNn"
      },
      "source": [
        "lines = []\n",
        "for i in file:\n",
        "    lines.append(i)\n",
        "\n",
        "data = \"\"\n",
        "for i in lines:\n",
        "    data = ' '. join(lines)\n",
        "    "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "EnCszrbB5WOk",
        "outputId": "47765768-24fe-409e-9ccb-1ed42c5d36ec"
      },
      "source": [
        "data[:1500]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"There were little things that she simply could not stand. The sound of someone tapping their nails on the table. A person chewing with their mouth open. Another human imposing themselves into her space. She couldn't stand any of these things but none of them compared to the number one thing she couldn't stand which topped all of them combined.\\n It went through such rapid contortions that the little bear was forced to change his hold on it so many times he became confused in the darkness and could not for the life of him tell whether he held the sheep right side up or upside down. But that point was decided for him a moment later by the animal itself who with a sudden twist jabbed its horns so hard into his lowest ribs that he gave a grunt of anger and disgust.\\n The cab arrived late. The inside was in as bad of shape as the outside which was concerning and it didn't appear that it had been cleaned in months. The green tree air-freshener hanging from the rearview mirror was either exhausted of its scent or not strong enough to overcome the other odors emitting from the cab. The correct decision in this case was to get the hell out of it and to call another cab but she was late and didn't have a choice.\\n The words hadn't flowed from his fingers for the past few weeks. He never imagined he'd find himself with writer's block but here he sat with a blank screen in front of him. That blank screen taunting him day after day had started to play with his mind. He didn't understand why \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uq2HFkzD8D3i"
      },
      "source": [
        "Split the data set into lines "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "VK7DT5YbM7ot",
        "outputId": "be13da06-18ff-4eb7-aa22-5fa15f1b2ad0"
      },
      "source": [
        "data = data.split('\\n') \n",
        "data[0] "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"There were little things that she simply could not stand. The sound of someone tapping their nails on the table. A person chewing with their mouth open. Another human imposing themselves into her space. She couldn't stand any of these things but none of them compared to the number one thing she couldn't stand which topped all of them combined.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "f0WqU83sM-P7",
        "outputId": "289b7b60-6351-4987-bff2-49ab8937c2a1"
      },
      "source": [
        "data = data[253:] \n",
        "data[0] "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' According to the caption on the bronze marker placed by the Multnomah Chapter of the Daughters of the American Revolution on May 12 1939 “College Hall (is) the oldest building in continuous use for Educational purposes west of the Rocky Mountains. Here were educated men and women who have won recognition throughout the world in all the learned professions.”'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcugW3qGNHNg",
        "outputId": "6caee738-9d00-4fb1-a740-fc01b4eae2a5"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "748"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTM74Bq48OPN"
      },
      "source": [
        "Right now we have a list of the lines in the data. Now we are going to join all the lines and create a long string consisting of the data in continuous format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "lc_Q7F1SNJob",
        "outputId": "4b97196d-04bf-4467-950a-2287dbf72af9"
      },
      "source": [
        "data = \" \".join(data) \n",
        "data[:1000] "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' According to the caption on the bronze marker placed by the Multnomah Chapter of the Daughters of the American Revolution on May 12 1939 “College Hall (is) the oldest building in continuous use for Educational purposes west of the Rocky Mountains. Here were educated men and women who have won recognition throughout the world in all the learned professions.”  She looked at her little girl who was about to become a teen. She tried to think back to when the girl had been younger but failed to pinpoint the exact moment when she had become a little too big to pick up and carry. It hit her all at once. She was no longer a little girl and she stood there speechless with fear sadness and pride all running through her at the same time.  Turning away from the ledge he started slowly down the mountain deciding that he would that very night satisfy his curiosity about the man-house. In the meantime he would go down into the canyon and get a cool drink after which he would visit some berry patches'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAnVzs5o8T7Q"
      },
      "source": [
        "we can see that after passing data to clean_text we get the data in the required format without punctuations and special characters. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGD9yrU6NMzU",
        "outputId": "1294e6aa-9d09-41aa-ff56-ff722a5c94cd"
      },
      "source": [
        "def clean_text(doc): \n",
        " tokens = doc.split() \n",
        " table = str.maketrans('', '', string.punctuation) \n",
        " tokens = [w.translate(table) for w in tokens] \n",
        " tokens = [word for word in tokens if word.isalpha()] \n",
        " tokens = [word.lower() for word in tokens] \n",
        " return tokens \n",
        "tokens = clean_text(data) \n",
        "print(tokens[:50]) "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['according', 'to', 'the', 'caption', 'on', 'the', 'bronze', 'marker', 'placed', 'by', 'the', 'multnomah', 'chapter', 'of', 'the', 'daughters', 'of', 'the', 'american', 'revolution', 'on', 'may', 'hall', 'is', 'the', 'oldest', 'building', 'in', 'continuous', 'use', 'for', 'educational', 'purposes', 'west', 'of', 'the', 'rocky', 'mountains', 'here', 'were', 'educated', 'men', 'and', 'women', 'who', 'have', 'won', 'recognition', 'throughout', 'the']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiOzH4KnNST3",
        "outputId": "4e5217d3-43c0-41e9-ef9f-0e1d04e2c0b1"
      },
      "source": [
        "len(tokens)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45335"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZ-XM27q8eLT"
      },
      "source": [
        "we are going to use a set of previous words to predict the next word in the sentence. To be precise we are going to use a set of 50 words to predict the 51st word. Hence we are going to divide our data in chunks of 51 words and at the last we will separate the last word from every line. We are going to limit our dataset to 200000 words. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Evjcb38bNWXG",
        "outputId": "dc671b58-5210-45d2-8335-f2d8b58ccc37"
      },
      "source": [
        "length = 50 + 1 \n",
        "lines = [] \n",
        "for i in range(length, len(tokens)): \n",
        " seq = tokens[i-length:i] \n",
        " line = ' '.join(seq) \n",
        " lines.append(line) \n",
        " if i > 200000: \n",
        "   break \n",
        "print(len(lines)) "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45284\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxKEqmbd8np7"
      },
      "source": [
        "# Build LSTM Model and Prepare X and y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5PMITFf8ptO"
      },
      "source": [
        "import all the necessary libraries used to pre-process the data and create the layers of the neural network. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZly3XUnNZ_w"
      },
      "source": [
        "import numpy as np \n",
        "from tensorflow.keras.preprocessing.text import Tokenizer \n",
        "from tensorflow.keras.utils import to_categorical \n",
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2M5zpNX8w2s"
      },
      "source": [
        "We are going to create a unique numerical token for each unique word in the dataset.fit_on_texts() updates internal vocabulary based on a list of texts. texts_to_sequences() transforms each text in texts to a sequence of integers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dU6ppQtNj8r"
      },
      "source": [
        "tokenizer = Tokenizer() \n",
        "tokenizer.fit_on_texts(lines) \n",
        "sequences = tokenizer.texts_to_sequences(lines) "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcnp7EIF85I8"
      },
      "source": [
        "sequences containes a list of integer values created by tokenizer. Each line in sequences has 51 words. Now we will split each line such that the first 50 words are in X and the last word is in y. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQrnK79PNoeV",
        "outputId": "cb113581-cf6a-4c3c-aa63-cef361adfdfd"
      },
      "source": [
        "sequences = np.array(sequences) \n",
        "X, y = sequences[:, :-1], sequences[:,-1] \n",
        "X[0] "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1757,    2,    1, 1756,   30,    1, 1755, 1754, 1753,   67,    1,\n",
              "       1752, 1751,    9,    1, 1750,    9,    1, 1749, 1748,   30,  214,\n",
              "       1747,   37,    1, 1746,  480,   12, 1745,  384,   20, 1744,  445,\n",
              "       1743,    9,    1,  866, 1742,  210,   33, 1741, 1740,    4, 1739,\n",
              "         94,   40, 1738, 1737,  588,    1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QegZTdGU8-3p"
      },
      "source": [
        "vocab_size contains all the uniques words in the dataset. tokenizer.word_index gives the mapping of each unique word to its numerical equivalent. Hence len() of tokenizer.word_index gives the vocab_size "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okeGAyr_NrR3"
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8effgz39FP-"
      },
      "source": [
        "to_categorical() converts a class vector (integers) to binary class matrix. num_classes is the total number of classes which is vocab_size. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26xBbJicNwk4"
      },
      "source": [
        "y = to_categorical(y, num_classes=vocab_size) "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqYquE9DNzpA",
        "outputId": "db8452d2-8d6f-42c8-a676-1eaf1c5f92e6"
      },
      "source": [
        "seq_length = X.shape[1] \n",
        "seq_length \n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7EN3dLX9Lb1"
      },
      "source": [
        "# LSTM Model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDDP2BxG9NKp"
      },
      "source": [
        "A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZiz_D2FN3at"
      },
      "source": [
        "model = Sequential() \n",
        "model.add(Embedding(vocab_size, 50, input_length=seq_length)) \n",
        "model.add(LSTM(100, return_sequences=True)) \n",
        "model.add(LSTM(100)) \n",
        "model.add(Dense(100, activation='relu')) \n",
        "model.add(Dense(vocab_size, activation='softmax')) "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyFqwA4BN9DW",
        "outputId": "242ab376-92e0-4797-f4c1-ab2b5042cc53"
      },
      "source": [
        "model.summary() "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 50, 50)            91500     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 50, 100)           60400     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1830)              184830    \n",
            "=================================================================\n",
            "Total params: 427,230\n",
            "Trainable params: 427,230\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeFmKQerOVan"
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uoig8K2B9WRQ"
      },
      "source": [
        "After compiling the model we will now train the model using model.fit() on the training dataset. We will use 100 epochs to train the model. An epoch is an iteration over the entire x and y data provided. batch_size is the number of samples per gradient update i.e. the weights will be updates after 256 training examples. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxxIK_7qOa1E",
        "outputId": "63ff9e72-a33a-4d0b-9cff-44665c92646d"
      },
      "source": [
        "model.fit(X, y, batch_size = 256, epochs = 100) "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "177/177 [==============================] - 6s 15ms/step - loss: 6.1976 - accuracy: 0.0554\n",
            "Epoch 2/100\n",
            "177/177 [==============================] - 3s 14ms/step - loss: 5.8524 - accuracy: 0.0587\n",
            "Epoch 3/100\n",
            "177/177 [==============================] - 3s 14ms/step - loss: 5.4975 - accuracy: 0.0726\n",
            "Epoch 4/100\n",
            "177/177 [==============================] - 3s 14ms/step - loss: 5.2128 - accuracy: 0.0887\n",
            "Epoch 5/100\n",
            "177/177 [==============================] - 3s 14ms/step - loss: 4.9513 - accuracy: 0.1082\n",
            "Epoch 6/100\n",
            "177/177 [==============================] - 3s 14ms/step - loss: 4.7444 - accuracy: 0.1207\n",
            "Epoch 7/100\n",
            "177/177 [==============================] - 3s 14ms/step - loss: 4.5566 - accuracy: 0.1280\n",
            "Epoch 8/100\n",
            "177/177 [==============================] - 3s 14ms/step - loss: 4.3639 - accuracy: 0.1377\n",
            "Epoch 9/100\n",
            "177/177 [==============================] - 3s 14ms/step - loss: 4.1747 - accuracy: 0.1521\n",
            "Epoch 10/100\n",
            "177/177 [==============================] - 3s 14ms/step - loss: 3.9904 - accuracy: 0.1651\n",
            "Epoch 11/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 3.8255 - accuracy: 0.1835\n",
            "Epoch 12/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 3.6655 - accuracy: 0.2013\n",
            "Epoch 13/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 3.5162 - accuracy: 0.2231\n",
            "Epoch 14/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 3.3722 - accuracy: 0.2445\n",
            "Epoch 15/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 3.2354 - accuracy: 0.2686\n",
            "Epoch 16/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 3.0999 - accuracy: 0.2901\n",
            "Epoch 17/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 2.9705 - accuracy: 0.3134\n",
            "Epoch 18/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 2.8395 - accuracy: 0.3404\n",
            "Epoch 19/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 2.7138 - accuracy: 0.3628\n",
            "Epoch 20/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 2.6009 - accuracy: 0.3893\n",
            "Epoch 21/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 2.4868 - accuracy: 0.4112\n",
            "Epoch 22/100\n",
            "177/177 [==============================] - 3s 14ms/step - loss: 2.3813 - accuracy: 0.4329\n",
            "Epoch 23/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 2.2844 - accuracy: 0.4551\n",
            "Epoch 24/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 2.1936 - accuracy: 0.4739\n",
            "Epoch 25/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 2.1059 - accuracy: 0.4930\n",
            "Epoch 26/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 2.0304 - accuracy: 0.5123\n",
            "Epoch 27/100\n",
            "177/177 [==============================] - 3s 14ms/step - loss: 1.9476 - accuracy: 0.5298\n",
            "Epoch 28/100\n",
            "177/177 [==============================] - 3s 14ms/step - loss: 1.8792 - accuracy: 0.5463\n",
            "Epoch 29/100\n",
            "177/177 [==============================] - 3s 14ms/step - loss: 1.8124 - accuracy: 0.5590\n",
            "Epoch 30/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 1.7568 - accuracy: 0.5738\n",
            "Epoch 31/100\n",
            "177/177 [==============================] - 3s 14ms/step - loss: 1.6941 - accuracy: 0.5854\n",
            "Epoch 32/100\n",
            "177/177 [==============================] - 3s 14ms/step - loss: 1.6268 - accuracy: 0.6037\n",
            "Epoch 33/100\n",
            "177/177 [==============================] - 3s 14ms/step - loss: 1.5732 - accuracy: 0.6163\n",
            "Epoch 34/100\n",
            "177/177 [==============================] - 3s 14ms/step - loss: 1.5134 - accuracy: 0.6321\n",
            "Epoch 35/100\n",
            "177/177 [==============================] - 3s 14ms/step - loss: 1.4708 - accuracy: 0.6412\n",
            "Epoch 36/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 1.4115 - accuracy: 0.6571\n",
            "Epoch 37/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 1.3677 - accuracy: 0.6658\n",
            "Epoch 38/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 1.3269 - accuracy: 0.6771\n",
            "Epoch 39/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 1.2692 - accuracy: 0.6934\n",
            "Epoch 40/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 1.2230 - accuracy: 0.7041\n",
            "Epoch 41/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 1.1933 - accuracy: 0.7071\n",
            "Epoch 42/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 1.1524 - accuracy: 0.7210\n",
            "Epoch 43/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 1.1076 - accuracy: 0.7325\n",
            "Epoch 44/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 1.0782 - accuracy: 0.7414\n",
            "Epoch 45/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 1.0412 - accuracy: 0.7499\n",
            "Epoch 46/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 1.0071 - accuracy: 0.7576\n",
            "Epoch 47/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.9678 - accuracy: 0.7687\n",
            "Epoch 48/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.9369 - accuracy: 0.7779\n",
            "Epoch 49/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.9007 - accuracy: 0.7876\n",
            "Epoch 50/100\n",
            "177/177 [==============================] - 3s 14ms/step - loss: 0.8767 - accuracy: 0.7923\n",
            "Epoch 51/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.8479 - accuracy: 0.8005\n",
            "Epoch 52/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.8074 - accuracy: 0.8105\n",
            "Epoch 53/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.7853 - accuracy: 0.8171\n",
            "Epoch 54/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.7538 - accuracy: 0.8259\n",
            "Epoch 55/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.7274 - accuracy: 0.8330\n",
            "Epoch 56/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.6998 - accuracy: 0.8400\n",
            "Epoch 57/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.6823 - accuracy: 0.8435\n",
            "Epoch 58/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.6560 - accuracy: 0.8513\n",
            "Epoch 59/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.6323 - accuracy: 0.8559\n",
            "Epoch 60/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.6135 - accuracy: 0.8618\n",
            "Epoch 61/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.5896 - accuracy: 0.8680\n",
            "Epoch 62/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.5633 - accuracy: 0.8763\n",
            "Epoch 63/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.5505 - accuracy: 0.8776\n",
            "Epoch 64/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.5236 - accuracy: 0.8855\n",
            "Epoch 65/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.5146 - accuracy: 0.8851\n",
            "Epoch 66/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.5032 - accuracy: 0.8900\n",
            "Epoch 67/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.4805 - accuracy: 0.8942\n",
            "Epoch 68/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.4587 - accuracy: 0.9000\n",
            "Epoch 69/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.4433 - accuracy: 0.9047\n",
            "Epoch 70/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.4280 - accuracy: 0.9083\n",
            "Epoch 71/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.4186 - accuracy: 0.9090\n",
            "Epoch 72/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.3933 - accuracy: 0.9181\n",
            "Epoch 73/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.3834 - accuracy: 0.9198\n",
            "Epoch 74/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.3624 - accuracy: 0.9268\n",
            "Epoch 75/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.3658 - accuracy: 0.9229\n",
            "Epoch 76/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.3527 - accuracy: 0.9259\n",
            "Epoch 77/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.3374 - accuracy: 0.9315\n",
            "Epoch 78/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.3182 - accuracy: 0.9354\n",
            "Epoch 79/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.3120 - accuracy: 0.9373\n",
            "Epoch 80/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.3026 - accuracy: 0.9389\n",
            "Epoch 81/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.3174 - accuracy: 0.9333\n",
            "Epoch 82/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.2844 - accuracy: 0.9422\n",
            "Epoch 83/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.2714 - accuracy: 0.9462\n",
            "Epoch 84/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.2630 - accuracy: 0.9468\n",
            "Epoch 85/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.2494 - accuracy: 0.9511\n",
            "Epoch 86/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.2562 - accuracy: 0.9491\n",
            "Epoch 87/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.2447 - accuracy: 0.9512\n",
            "Epoch 88/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.2365 - accuracy: 0.9535\n",
            "Epoch 89/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.2325 - accuracy: 0.9540\n",
            "Epoch 90/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.2264 - accuracy: 0.9551\n",
            "Epoch 91/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.2244 - accuracy: 0.9553\n",
            "Epoch 92/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.2117 - accuracy: 0.9590\n",
            "Epoch 93/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.1989 - accuracy: 0.9615\n",
            "Epoch 94/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.1986 - accuracy: 0.9616\n",
            "Epoch 95/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.1978 - accuracy: 0.9603\n",
            "Epoch 96/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.1847 - accuracy: 0.9647\n",
            "Epoch 97/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.1805 - accuracy: 0.9639\n",
            "Epoch 98/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.1880 - accuracy: 0.9624\n",
            "Epoch 99/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.2255 - accuracy: 0.9510\n",
            "Epoch 100/100\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 0.1823 - accuracy: 0.9628\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fda27d62710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnCMJlWo9e7D"
      },
      "source": [
        "We are now going to generate words using the model. For this we need a set of 50 words to predict the 51st word. So we are taking a random line."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "yAi3xW_yOdyn",
        "outputId": "280b1d92-d78b-4180-d967-12296d9eb75d"
      },
      "source": [
        "seed_text=lines[12343] \n",
        "seed_text "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'her husband lamenting at fate which had directed her footsteps to the path which they had taken she was just having a good cry all to herself the mosquitoes made merry over her biting her firm round arms and nipping at her bare insteps it was easy to spot her all'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykdGfHz19lW6"
      },
      "source": [
        "generate_text_seq() generates n_words number of words after the given seed_text. We are going to pre-process the seed_text before predicting. We are going to encode the seed_text using the same encoding used for encoding the training data. Then we are going to convert the seed_textto 50 words by using pad_sequences(). Now we will predict using model.predict_classes(). After that we will search the word in tokenizer using the index in y_predict. Finally we will append the predicted word to seed_text and text and repeat the process. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUhuB6AaOnKf"
      },
      "source": [
        "def generate_text_seq(model, tokenizer, text_seq_length, seed_text, n_words): \n",
        " text = [] \n",
        " for _ in range(n_words):\n",
        "   encoded = tokenizer.texts_to_sequences([seed_text])[0] \n",
        "   encoded = pad_sequences([encoded], maxlen = text_seq_length, truncating='pre') \n",
        "   y_predict = model.predict_classes(encoded) \n",
        "   predicted_word = '' \n",
        "   for word, index in tokenizer.word_index.items(): \n",
        "     if index == y_predict: \n",
        "       predicted_word = word \n",
        "       break \n",
        "   seed_text = seed_text + ' ' + predicted_word \n",
        "   text.append(predicted_word) \n",
        " return ' '.join(text) "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XQqspVF9sQR"
      },
      "source": [
        "We can see that the next 100 words are predicted by the model for the seed_text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "jn_bNqdOOskE",
        "outputId": "889b6b5f-486b-43af-f971-4f65cb4d55d1"
      },
      "source": [
        "generate_text_seq(model, tokenizer, seq_length, seed_text, 100) "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'you needed to do was look at her socks they were never a matching pair one would be green while the other would be blue one would reach her knee while the other barely touched her ankle every other part of her was perfect but never the socks they were her micro act of rebellion she sat across from her trying to imagine it was the first time it wasnt had it been a expert or much away with him the lone lamp post of the onestreet town flickered not quite dead but definitely on its way out suitcase by'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJiuTAvJ-KTd"
      },
      "source": [
        "We have got a accuracy of 96%. To increase the accuracy we can increase the number of epochs or we can consider the entire data for training. For this model we have only considered 1/4th of the data for training. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbCI4br0OwFX"
      },
      "source": [
        ""
      ],
      "execution_count": 24,
      "outputs": []
    }
  ]
}